# Introduction {#sec-introduction}

Artificial intelligence (AI) has become a headline topic in today's news, capturing the attention of individuals across various fields eager to leverage its capabilities to enhance their work. Historically, computers were introduced to take on repetitive and mundane tasks, leading to significant advancements in processing speed, communication infrastructures, and storage capacities. However, with the advent of sophisticated AI algorithms, we are now faced with a new level of challenges and solutions.

In the past, problem-solving involved identifying the issue and explicitly programming the computer to transform input data into desired outputs. Software specialists had to meticulously define every step of the problem-solving process to achieve the correct outcome. This traditional method required a deep understanding of the problem and the logic needed to solve it.

The emergence of AI, however, has revolutionized this approach. Instead of explicitly programming each step, we now provide the system with vast amounts of data, allowing it to "learn" and adjust itself to achieve the desired results. This learning process enables AI to tackle problems that were previously unsolvable using classical methods. By training models with large datasets, AI systems develop the capability to make predictions, recognize patterns, and generate insights without human intervention in the learning process.

This shift from explicit programming to AI opens up possibilities for addressing complex problems across diverse domains. The challenge now lies in selecting the appropriate type of learning—supervised, unsupervised, or reinforcement learning—based on the nature of the problem and the available data. Understanding the strengths and limitations of each learning type is essential for effectively harnessing AI to solve real-world problems. From art and entertainment to industry, manufacturing, and healthcare, AI's transformative impact is evident. These developments highlight the need for individuals and organizations to embrace AI, as leveraging its potential can drive innovation, efficiency, and improvements across various domains. As AI continues to evolve, integrating it into diverse fields becomes increasingly crucial. Therefore, understanding and utilizing AI is essential to remain competitive and progressive.

## Problem Statement

This thesis stems from a research project that explored using AI solutions to improve structural analysis, specifically by optimizing design parameters in Structural simulations. The goal is to enhance the efficiency and accuracy of engineering analyses. The thesis will further detail how AI - or more specifically machine learning - can be integrated into these workflows, aiming to identify effective models, reduce computational costs, and improve decision-making in engineering design. Individuals involved in this process are highly skilled experts, and their involvement represents a significant investment for the industry. Given the complexity and precision required in these tasks, even small improvements in efficiency can lead to substantial cost savings, increased profitability, and significant time savings. Streamlining their workflow, whether through automation or enhanced tools, has the potential not only to reduce expenses but also to accelerate project timelines, allowing companies to bring products to market faster and gain a competitive edge.

### ML\@Karoprod Project

The BMBF project titled "Machine Learning for the Prediction of Process Parameters and Component Quality in Automotive Body Production (ML\@Karoprod)" focuses on optimizing process parameters in a product chain for deforming a metal plate through a series of operations. In this project, conducted in collaboration with TU Chemnitz, IWU Fraunhofer Dresden, and SCALE GmbH, the aim was to leverage the machine learning methods to ensure high-quality products. Traditionally, an expert conducts process simulations, adjusts parameters, and evaluates the results to achieve the desired shape. This iterative process, which takes about 20 minutes per cycle, is repeated until the desired accuracy is reached, with the expert manually making the necessary adjustments and running further simulations.

![Process in action - IWU Fraunhofer Dresden](img/Chp1/karo_process.png){#fig-karo-proc fig-align="center" width="50%"}

The process begins with deep drawing, a sheet metal forming technique where a metal blank is radially drawn into a forming die by a punch, with the goal of producing a wrinkle-free and crack-free product. Our simulated deep drawing data consists of a number of valid experiments, each characterized by various process parameters. In collaboration with our partners, the relevant set of features that are necessary and sufficient to fully determine the effects of a simulation were identified. The features were divided into numerical and categorical types. That is, numerical features represented continuous values (the sheet thickness (from 0.99 to 1.48 mm) the blank-holder force (from 10 to 500 kN) and the insertion position (-5 to +5 mm)), while categorical features represented distinct classes or groups (the drawing depth (30, 50, or 70 mm) the drawing gap (1.6 or 2.4 mm)). To represent the different materials and stamps, IDs were assigned to uniquely identify each type of feature.

![from blank metal sheets to the product](img/Chp1/pikaso_enhance__none_2K_Standard_r_c_.jpeg){#fig-karo-hq fig-align="center" width="50%"}

![For each set of parameters in a row, one mesh were provided.](img/Chp1/table_params.png){#table-params fig-align="center" width="50%"}

Approximately 1000 simulation files in mesh format were generated by the project partner by varying process parameters. After data cleaning, about 880 of these files were usable. The meshes had three different geometries (with three different depths: 30, 50, and 70 shown in @fig-zt), and parameters such as force and material varied, resulting in different final mesh outcomes. The ultimate goal in this section was to train a neural network to predict the dependency between changes in input parameters and the generated mesh. With sufficient training, the model would be able to accurately predict the shape of the final mesh even with new inputs that were not seen during training. This allows the specialist to quickly and accurately observe the final simulation results by manipulating parameters, in a much shorter time compared to traditional finite element methods.

![a view of three different meshes with different drawing depths : 30,50,70.](img/Chp1/z70-50-30.png){#fig-zt fig-align="center" width="50%"}

## Metal Deformation Process

Deformation refers to the change in shape, size, or position of a material or structure when subjected to external forces, such as tension, compression, shear, bending, or torsion. This alteration occurs due to the displacement of particles within the material, resulting in either elastic deformation, where the material returns to its original shape after the removal of the force, or plastic deformation, where the change is permanent. Single-step deformation (SSD) in our context refers to the process of applying a force to a structure or material in a single instance, resulting in a one-time deformation.

In practice, what engineers do is resort to simulations to reduce costs and increase accuracy and speed, using tools like Finite Element Methods (FEM) for this purpose. An expert needs to design the geometry in the software, perform meshing, and then define the fixed and force constraints. After that, they must select the material and choose an appropriate solver, depending on the complexity of the geometry and the problem, as well as the computational power available, and then wait for the simulation results. This process can even take several days, and in the end, the expert evaluates the parameters based on the simulation results. It is usually necessary for the expert to adjust some parameters (based on their experience and knowledge) and rerun the simulation. As it might seem, this can be a challenging process for experts. Moreover, in industry, this can be quite costly because, alongside powerful equipment, a significant amount of time and energy from an expert is required to address a single problem. Therefore, any improvement in this process can be very beneficial and profitable.

The focus of this thesis is on a specific type of deformation that occurs when pressure or force is applied to the surface of a metal piece, causing it to change shape. While this type of deformation is relatively simple, it has a wide range of applications.

## Leveraging NN for Metal Deformation Process

### Standard dataset for training and benchmark
The next issue is the dataset. Unlike standard datasets available for images, videos, and text, there is no publicly accessible deformation dataset with a large volume of data for this specific case, which limits the ability to compare and test models. Some data has been provided by the project partner, and it was decided that a dataset would be generated for training the model in the 3D space.

### the size of dataset and data units
In most existing works involving 3D data, the entire 3D object is fed into the network at once, meaning that the input unit is the mesh, and the network learns based on this input in each iteration. As a result, large datasets with meshes containing a high number of vertices significantly increase the size of the network, particularly in the input layer and subsequently in the following layers. This leads to a substantial increase in computational complexity and the number of parameters in the network. Consequently, it becomes necessary to increase both the number of training samples and the number of training epochs. However, generating a large volume of data for the network is often impractical. In our specific case, we have around 1,000 meshes, each ranging between 13,000 and 16,000 vertices in size.

If 3D meshes with around 13,000 to 16,000 vertices are fed directly into a neural network, the input layer size will be proportional to the number of vertices. For instance, using 3D coordinates (x, y, z), the input layer would have 3 neurons per vertex. Therefore, the input size for each mesh would be calculated as follows: For 13,000 vertices: 13,000×3=39,000 input neurons.
In most neural networks, the input layer is followed by fully connected layers. If the first hidden layer contains 1,000 neurons, the number of parameters (weights) between the input layer and the first hidden layer would be: For 13,000 vertices: 39,000×1,000=39,000,000 parameters.

This number can increase rapidly as additional hidden layers or larger layers are added, and it does not yet account for biases or further layer connections. Even this simplified model would have tens of millions of parameters. To ensure generalization and prevent overfitting, a sufficient number of data samples is required. A common rule of thumb in machine learning suggests having at least 10 times more training examples than parameters, though this varies depending on the data and model complexity. For 39,000,000 parameters (based on the 13,000 vertex case), at least 390 million data points would be needed for effective training. Given the large number of parameters, having only 1,000 meshes with 13,000–16,000 vertices may be insufficient, posing a risk of overfitting. Ideally, 10,000–50,000 samples would be necessary, or techniques such as downsampling or using specialized architectures should be considered to reduce input size.

### Combining 3D Data and NN - 3D Data Formats
When applying neural networks to deformation problems, several challenges emerge, with the first being the selection of an appropriate 3D data input format. Neural networks are typically designed to process structured inputs of fixed size. For example, in image processing, the input is a regular grid of pixels with a consistent and specific order. However, 3D data does not usually follow this regular grid structure, making it difficult to directly feed into traditional architectures like convolutional neural networks (CNNs). 3D data can vary in resolution, topology, and structure, complicating the task of maintaining a fixed input size. Furthermore, the inherent complexity of 3D data presents additional challenges in preserving spatial relationships and geometric features, both of which are essential for accurately modeling deformation. Overcoming these obstacles is crucial for successfully leveraging neural networks in 3D deformation tasks. Here is why these discrete representations are not ideal for describing deformation with neural networks:

#### Mesh
Meshes are commonly used in representing 3D objects, especially in finite element analysis and computer graphics. However, for neural networks, especially traditional architectures like convolutional networks, meshes present a challenge due to their irregular structure. Meshes consist of vertices and edges that form triangular or polygonal faces, and the number of vertices can vary across different objects. This lack of uniformity in structure makes it difficult to apply neural networks that require fixed input sizes. Additionally, the connectivity between vertices (topology) adds complexity, making it harder for neural networks to learn deformation patterns consistently across different meshes. The irregularity and large size of meshes also lead to increased computational demands and parameter counts, which can make training inefficient.

#### Point Cloud
Point clouds represent 3D data as a collection of discrete points in space, which describe the surface of an object without explicitly encoding the connectivity between points. While point clouds provide a simple and direct way to capture 3D shapes, they lack inherent structure and order, making it challenging for neural networks to process them effectively. The unordered nature of point clouds means that traditional neural network architectures like CNNs, which rely on spatial relationships, cannot be directly applied. Additionally, point clouds may vary in density and resolution, which can further complicate the learning of deformation, as small deformations might not be accurately captured depending on the point sampling. Handling the lack of connectivity information also makes learning the geometry of deformations more difficult.

#### Voxel
Voxels represent 3D space as a grid of volumetric pixels, similar to 2D pixels but in three dimensions. Although this regular grid structure can be directly fed into convolutional neural networks, voxel representations suffer from a significant drawback: memory inefficiency. Voxel grids require vast amounts of memory to represent high-resolution 3D objects, especially when capturing fine details of deformation. The resolution must be very high to model small deformations accurately, which dramatically increases the computational cost. In addition, the sparse nature of 3D objects (with most voxels being empty) leads to inefficient usage of both memory and computational resources, making voxel-based representations impractical for many deformation tasks.

#### Depth Image
Depth images capture the distance between the camera and the surface of objects, representing 3D structures in a 2D format. While they offer the advantage of being easily processed by traditional CNNs due to their image-like structure, depth images inherently lose information about the object’s geometry, especially in areas not visible from the camera's perspective. This loss of data makes it difficult to fully capture the shape of an object, particularly in deformation scenarios where understanding the entire 3D structure is crucial. Additionally, since depth images are viewpoint-dependent, multiple images from different angles would be required to capture the full deformation, which introduces further complexity in the data preprocessing and network design.

Each of these data representations poses unique challenges when used to describe deformations with neural networks. Their limitations in terms of structure, memory efficiency, and ability to capture complex geometric relationships make them less than ideal for modeling 3D deformation tasks. These challenges necessitate the development of specialized architectures or preprocessing techniques to overcome their inherent shortcomings when applied to neural networks.

### Key Solution: Insights from Implicit Representations
So far, it has been shown that discrete data representations pose significant challenges when applied to deformation using neural networks. As the research progressed, a more suitable combination of neural networks with 3D data was identified, which, with certain adjustments, appeared well-suited for representing deformation. The initial inspiration came from the paper on DeepSDF. In this work, neural networks were used as embedding functions for 3D objects, resulting in a relatively small network capable of embedding high-resolution meshes. Additionally, the approach is independent of topology, providing an accurate representation of geometry, which is crucial for deformation tasks. Despite introducing a novel representation method and training a neural network accordingly, this paper did not explicitly address deformation. It appeared, however, that the method could be adapted to deformation-related tasks after some modifications.

#### 

## Research Questions

So far, the research topic has been discussed, and preliminary discussions have been made regarding familiarization with FEM and the existing challenges. Additionally, we provided a brief overview of neural networks and their components, as well as commonly used algorithms and key considerations. This research has been conducted to answer the following questions:

-   combine NN and 3D data for modeling the object deformation
-   investigating the best match for modeling the 3D data and neural networks to develop techniques to balance neural network size, accuracy, and computational efficiency
-   Investigating how implicit representations can replace traditional mesh processing methods in 3D models
-   examining the potential benefits of continuous model representations
-   Identifying methods to reduce simulation times for complex 3D models using implicit representations
-   Deriving and optimizing an accurate set of process parameters from neural networks for handling the dynamics of 3D shapes, particularly for real-time applications.

In the next chapter, the work done in the area of the Finite Element Method using AI techniques will be reviewed. The next chapter will address data, covering various forms of 3D representation and datasets, as well as the steps taken in generating them. Additionally, the chapter will detail the preparation of the data for training the neural network. In the following chapter, single-step deformation will be examined, focusing on both shell meshes and solid meshes. Multi-step deformation will then be explored in the subsequent chapter, incorporating reinforcement learning to enhance the process using mesh data, image data and 3D implicit fields. Finally, the research will conclude with a comprehensive analysis of the results and insights derived from the study.

## list of publications