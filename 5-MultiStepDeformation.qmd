# Multi Step Deformation {#sec-msd}

## Multi Step Deformation

This chapter explores the multi-step deformation (MSD) process of a cuboid that is fixed at the bottom while sequential force vectors are applied to the top. The objective is to achieve a desired shape through a series of deformations. Here, I used Reinforcement Learning (RL) because it excels in sequential decision-making and learning optimal strategies through trial and error, making it ideal for optimizing the deformation sequence to achieve precise outcomes. World Models, such as PlaNet or Dreamer, are utilized because they effectively learn compact representations of the environment dynamics, enabling efficient planning and control. By combining RL with these World Models, we can accurately predict deformation outcomes and optimize the sequence of applied forces, ensuring a smooth and continuous transformation of the initial cuboid into the desired shape.

![deformed mesh in 5 steps](img/Chp3/mesh_states.png){#fig-mesh-states fig-align="center" width="40%"}

As we need to keep track of the state changes, the predictor NN should contain the state information.

The Cross Entropy Method (CEM) is employed to identify the optimal sequence of force vectors (actions) through several key steps. At first, a distribution over possible force vectors is initialized. From this distribution, a set of action sequences is sampled. Each sequence is then evaluated by simulating the deformation process using the neural network, with performance measured by comparing the deformed shape to the desired shape. Based on these evaluations, the distribution is updated to focus on better-performing sequences, increasing the likelihood of sampling optimal sequences in subsequent iterations. This iterative process continues until the deformation sequence converges to an optimal solution.

The optimization continues until a convergence criterion is met. The criterion is defined based on the similarity between the deformed and the target shape. Once convergence is achieved, the final sequence of force vectors represents the optimal strategy for achieving the desired deformation. First we tried 2D approach and then continued with both mesh and implicit representation of the 3D and compare the methods.

### Problem Definition in RL

state^t^ : the cuboid shape in time t

action^t^ : force vector

state^t+1^ : the cuboid shape in time t+1

and The transition function that models how the state changes due to the applied action:

$$
\text{state}_{t+1} = f_{\text{transition}}(\text{state}_t, \text{action}_t)
$$

I solved the problem with 2D and 3D approaches, that will be explained in the next sections.

## 2D Approach - Image based

As the cuboid is only subjected to force from the top, an image of the top surface can adequately represent the entire shape. For this purpose, I selected the top vertices of the mesh and used the 'Kriging' method from Openturns library @baudin2015open to interpolate the z-values across the entire surface. Kriging @cressie2015statistics also known as "Gaussian process regression", is a method of interpolation based on a Gaussian process governed by prior covariances. It is widely used in spatial analysis and computer experiments to predict values of a spatially distributed variable from sparse data points. Under suitable assumptions of the prior, Kriging provides the Best Linear Unbiased Prediction (BLUP) at unsampled locations, outperforming other interpolation methods based on criteria such as smoothness (e.g., smoothing spline). By considering both the distance and the degree of variation between known data points, Kriging generates a smooth, continuous surface that accurately reflects underlying spatial trends, making it ideal for interpolating from sparse pixels to a smooth image. \[image size: 20x50\]

Ordinary Kriging has been used here because it assumes the process mean to be constant and unknown. By utilizing a covariance model (specifically, the SquaredExponential covariance model) and the openturns Kriging algorithm, the Kriging metamodel can be fitted using the provided coordinates and observations. These characteristics align well with the Ordinary Kriging method, as accurate spatial data estimations can be provided. Originally developed for geostatistical applications, Kriging is a versatile statistical interpolation method used across various disciplines for sampled data from random fields that meet certain mathematical assumptions. It is particularly useful for estimating data in the spatial gaps between measured points, whether the data is collected in 2D or 3D.

![the depth image of the top surface (left) top vertices visualized on top surface as circles (right) the color shows the depth (z)](img/Chp3/kriging_1.png){fig-align="center" width="40%"}

![the regular grid interpolated using kriging method](img/Chp3/kriging_2.png){#fig-krig2 fig-align="center" width="40%"}

![the deformed shape and its corresponding top image](img/Chp3/mesh_krig.png){#fig-mesh-krig fig-align="center" width="40%"}

### World Model

the world model is our predictor, in a latent space domain. the WMs can be trained offline or online to reflect the effect of the Force (as action) on the compressed version of the state (shape). first I compressed the data utilizing a Conditional ConvolutionalAutoencoder. My model includes an encoder-decoder structure, where the encoder comprises two convolutional layers with ReLU activation functions and max pooling operations to progressively reduce the spatial dimensions while increasing feature depth. The latent space is further manipulated through linear layers that incorporate external conditioning information. The decoder then reconstructs the original input using two deconvolutional layers, aiming to produce an output that closely resembles the initial data. The CCAE is trained to minimize the reconstruction loss, making it suitable for image compression.

n_latent: compression rate ##todo the best parameters - reported from HPO : ...

![from initial state to final state - NN prediction of states](img/Chp3/cem_2d_seq.png){fig-align="center" width="80%"}

the proposed approach is limited to top surface and can not effectively generalize to 3D. however has an acceptable accuracy and performance and could be applied for similar problems such as \[# todo examples\] where the 2D prediction would be sufficient.

## 3D Approach - Vertex based

instead of converting the top surface to the image, we could directly work on 3D coordinates of vertices on top. in this approach, the NN input would be the same as number of top vertices coordinates (x,y,z) , so usually we could have a smaller NN. as the order of NN inputs are important, we need to keep the topology fixed and assure that the order of vertices is remained fix.

Here I -manually- kept the topology fixed. therefore, my vertices have index and they are ordered. so I trained a simple MLP that directly receives the xyz coordinates of the top vertices and the action , to predict the next placement of vectors. as in real, it rarely happens that we have a mesh dataset with identical topology for all samples, that would be an easy and low-cost approach if needed. the same as image approach, all data ( here vertices' coordinates ) corresponding to each state, is fed to the network at once. so the network has a "global" view of each state.

as the data size is relatively small, the vertex positions could be applied in RL loop directly. the network has the size of - - - layers , optimized by --. error plots... #todo

## 3D Approach - Mesh based

For processing the mesh data, we needed to compress the meshes utilizing the well-known CoMA @ranjan2018generating generating model. the Mesh autoencoder is trained to minimize the reconstruction error on our mesh dataset and using HPO, the best set of parameters are selected. So the trained encoder is now utilized to encode all meshes in the dataset in offline mode.

#todo HPO parameters , mish activation function, compression rate

The encoded meshes are again collected in a form of a dataset to train the WM. During the training of the World Model, the neural network is fed with \[State_t, action_t\] as input, to predict the State_t+1. please notice that the state is the encoded shape or the so called latent representation of the mesh.

the same as before, the PlaNet is used here, this time for encoded mesh representation. 
$$
\text{NN}([\text{State}_{t}, \text{action}_t]) \rightarrow \text{State}_{t+1}
$$

### Challenges of working with meshes

Working with meshes in combination with neural networks presents several fundamental challenges that we address: The first challenge is the lack of regular structure in mesh vertices, unlike the pixels in an image. Mesh vertices are scattered in three-dimensional space and cannot be easily vectorized from the top-left to the bottom-right like image pixels for input into the network. The second challenge is that the mesh structure must be presented to the neural network all at once, causing the network to become significantly large when dealing with a large mesh with many vertices, thereby increasing the number of learning parameters. The third challenge is that maintaining the mesh topology is very difficult and in many cases seems impossible. In tasks like physical simulation and finite element analysis, the resulting mesh needs to be re-meshed for reprocessing, which alters the mesh topology. (In my case however, I had to preserve the mesh topology manually!) Therefore, using alternative methods that can overcome these problems can be very helpful. In the next section, we introduce implicit methods that can serve as a good alternative to meshes and address these issues.

## 3D Approach - Implicit data

For SDF representation, a fixed grid is established, and the distance from the surface is calculated for all meshes within this grid. This grid is randomly sampled in the space surrounding the shape, both inside and near the surface. The fixed grid is essential for tracking distance values, as the network needs to be aware of the current state to predict the subsequent state. The inputs to the network are the xyz coordinates of the query point, the current SDF value at that point (SDF^t^), and action^~t~^ (a force vector) as a condition, with the output being SDF^t+1^.

![image caption](img/Chp3/net_sequence.png){#fig-implicit-net fig-align="center" width="80%"}

For visualization and evaluation, error metrics are used to compare predicted values with target values in the test set. The test set includes various mesh sequences selected from the dataset to assess our method. Since the current SDF for each point is necessary to predict the next SDF value, the process starts from the initial (undeformed) mesh to generate SDF values sequentially. Initially, an SSD (Single-Step Deformation) Network is used, followed by MSD (Multi-Step Deformation) Networks to predict subsequent SDF values.

This SSD Network is trained on undeformed mesh samples and are the same as model described in \[chapter X\]. the only difference is that, the query points are chosen from our fixed grid point. also a new input (sdft) is fed to the network to represent the current sdf of the query point.

### Challenges of working with Implicit data

use of implicit data has a great benefit over explicit methods in applications such as reconstruction, classification etc. they have a good binding with NNs and small network size for embedding and encoding of 3d shapes. however in context of deformation, we need to have a global understanding of the shape - or state - to generalize the action ( Force ) effect on the whole body. as the data unit provided to the network is related to one point ( and not the whole shape ), here the network has a partial observation of the state each time.