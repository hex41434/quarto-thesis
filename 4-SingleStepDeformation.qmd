# Single Step Deformation {#sec-ssd}

Note: here the mesh was very dense, so the nn would consider it as a continuous rep. however contrary to PC methods, the points are individually provided to the network!

## Introduction

The meshing process plays a crucial role in simulations. For the meshes to be effective, they need to meet specific criteria. Often, they’re created with high density to ensure that complex shapes, like curves and corners, are captured accurately. Additionally, the mesh elements must have an appropriate aspect ratio to perform well in simulations. This can sometimes lead to the need for re-meshing, where the mesh is adjusted to better fit the requirements of the analysis. 

\[add image of good/ bad remsehing \]

For effective re-meshing in Finite Element Method (FEM) simulations, **Adaptive Re-Meshing** stands out as a top choice. This method adjusts the mesh density dynamically based on the solution's needs, such as stress concentrations or complex geometrical features. By refining the mesh where high accuracy is required, adaptive re-meshing ensures a balance between precision and computational efficiency, making it ideal for complex structural analyses.

Another excellent approach is **Curvature-Based Re-Meshing**, which focuses on refining the mesh in regions with high curvature to accurately capture the geometry's intricate details. This is particularly beneficial for simulations involving curved surfaces or sharp edges. **Error-Based Re-Meshing** is also highly effective, as it refines the mesh in response to error distributions observed in preliminary simulations. This method allows for iterative improvement of the mesh, leading to more accurate and reliable results in FEM analyses.

On the other hand, it is evident that with re-meshing, the mesh can no longer remain fixed, and at each stage, we encounter a new mesh depending on the requirements. This poses a challenge for using meshes in neural network modeling, as methods based on meshes with consistent topology become very limited. This was a strong reason for us to explore alternative methods that could define the geometry of the object and present it to the neural network independently of the mesh. Among the studied methods, implicit models showed better compatibility with neural networks. However, so far, not much work has been done on deformation using this type of data, which made the task more challenging.

![image caption](img/Chp3/interpolate_sdf_codes.png){#fig-sdf-interpolate fig-align="center" width="70%"}

### SSD on Watertight Mesh

For each object, the SDF function divides the space into three regions: points with positive distances, which are outside the object; points with negative distances, which are inside the object; and boundary points, which lie on the surface. Therefore, it is necessary for the object to have a closed or watertight geometry.

**SDF Function Estimation:**

Initially, a neural network, denoted as $f_\theta$ , is trained to estimate the Signed Distance Function for a given 3D object. For any point $p$ in the 3D space, the network outputs the SDF value, which indicates the distance of the point from the object's surface:

$$
SDF(p) = f_\theta(p) 
$$

Here, $p$ in $R^3$ is a point in the 3D space, and $\theta$ represents the parameters of the neural network.

**Deformation with Force Vector:**

Now, suppose a force vector $F$ is applied to the object. The goal is to condition the SDF estimation on this force vector and predict the SDF of the deformed object.

To achieve this, the neural network is extended to take the force vector $F$ as an additional input, resulting in a modified function:

$$
SDF_{deformed}(p, F) = f_\theta(p, F) 
$$

In this formulation:

-   $p$ is still the point in 3D space.
-   $F\in R^3$ represents the force vector applied to the object.
-   $SDF_{deformed}(p, F)$ is the SDF value of the deformed object at point $p$.

#### Training Neural Network

the designed neural network needs to map the 3D points in the space, to a corresponding SDF value, based on a provided force vector. similar to the DeepSDF paper, we choose a Multilayer Preceptron for this purpose. HPO

\*\* effect of different parameters on estimation -\> table

activation function, layers, arch , ....

conditional NN

#### Conclusion

So far, it has been demonstrated that this approach is feasible for predicting the deformation shape of watertight objects based on a single applied force. The designed network, despite its small size, is capable of processing large meshes because it is fundamentally independent of mesh structure. The compact size of the network also offers the advantage of faster training and testing speeds, allowing the trained network to predict deformations more quickly than previous methods.

### SSD on non-Watertight Mesh

Earlier, it was observed that the original DeepSDF algorithm is defined based on watertight meshes. But the data provided by our industrial partner, were large non-watertight meshes with a large number of vertices and faces. Therefore the original DeepSDF method could not be applied there directly.

instead we modify the input and train the neural network. the network could predict the thickness, thinning and deviation with an acceptable error.

#### 1D approach

We had approximately 880 meshes that were deformed by varying processing parameters. These parameters were more complex than a simple force vector and included the following: ... In total, the meshes had three different heights—30, 50, and 70 cm. For each model, we had several meshes with the same topology (as shown in the table). For each mesh, values of thickness, thinning, and deviation were recorded on each face, along with the processing parameters that caused the deformation. In the first step, a cross-section was cut through the middle of each mesh, and points were sampled along this cross-section. This provided a one-dimensional distribution of the thickness, thinning, and deviation values for each mesh sample. The goal was to design a neural network that would take the coordinates of each point on the cross-section along with the processing parameters as input and predict the thickness, thinning, and deviation values as output. This task was accomplished with excellent approximation and speed, and the results can be observed in the charts provided.

![image caption](img/Chp1/karo_1D.png){#fig-karo-1d-1 fig-align="center" width="100%"}

![a) Position of the x0 cut through the deep-drawn element. b) Deviations from the template for the 880 simulations. The three drawing depths (30, 50, and 70) are shown in different colors.](img/Chp1/karo_1D_cut.png){#fig-karo-1d-2 fig-align="center" width="100%"}

#### 2D approach

The deviation and thickness values are available not only along the cuts but for all vertices of the reference mesh. The values determined for each vertex of the 3D mesh can be projected onto a 2D plane using a cylindrical projection. Similar to the previous approach, we can train a model to predict the relevant attributes based on the projected 2D coordinates and the process parameters. We use a regression method based on random forests, but the principle remains the same as with neural networks. **Fig. N** shows the deviation and thickness values predicted by the model compared to the ground truth.

![Predicted values compared to the ground truth for the cylindrical projection (Experiment 742).](img/Chp1/karo_2D.jpg){#fig-karo-2d-1 fig-align="center" width="87%"}

network arch \[?] image grid? , HPO,...

#### 3D approach

providing the x,y,z coordinates of the mesh elements - or faces - and corresponding properties: thickness, thinning and deviation, the trained network could provide a good estimation of these properties.

By extending previous models into the third dimension, we designed a model capable of predicting the deformation, thickness, and thinning of the target component. The neural network receives the coordinates of each face and can estimate the corresponding characteristics. The designed network is small in size, resulting in lower complexity and faster execution speed, and it performs very quickly during inference. We also created a simple interface, incorporating parameters as sliders and radio buttons, allowing the user to adjust the desired parameters (both numerical and categorical) and see the deformation results within a few seconds. It’s worth noting that this process, when performed using the Finite Element Method for a similar component, takes approximately 20 minutes according to the project partners. Therefore, the execution of this code appears successful and efficient. Additionally, the model is capable of interpolating for parameters not present in the dataset and can provide higher-resolution predictions.

network arch, ... 

similar approach can be applied to the 3D mesh. We have access to the x-, y-, and z-coordinates of the center of each face of the reference mesh as well as the process parameters. These can be used similarly to the 1D cuts to predict the deviation at specific points of the reference mesh. The size of the dataset for each drawing depth "Zt" is described in the following table:

| Zt  | Number of faces per mesh | Number of simulations | Dataset size |
|-----|--------------------------|-----------------------|--------------|
| 30  | 26,759                   | 500                   | 13,379,500   |
| 50  | 28,587                   | 250                   | 7,146,750    |
| 70  | 31,976                   | 250                   | 7,994,000    |

#### Joining Process

These components can be attached together in pairs, so we tested whether our algorithm could also be applied to joining. In this case, the designed model must take the parameters of both components as input and output the placement and deformation of each component separately. In joining, the optimal condition occurs when the two components come as close as possible, minimizing the pocket size. The simulation results demonstrated that this method is also applicable for this purpose.

Z-position of the four clamps
A clinch ID for each part. 

+ The process parameters of the two deep-drawn parts

18 process parameters for joining 
